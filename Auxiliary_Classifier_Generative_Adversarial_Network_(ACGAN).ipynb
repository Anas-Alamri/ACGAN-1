{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Auxiliary Classifier Generative Adversarial Network (ACGAN).ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "c-R5meWZu3ts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd9e1c53-064e-42d6-ea87-5c27dff17814"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "cJBlJ94Mu3t6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "from collections import defaultdict\n",
        "try:\n",
        "    import cPickle as pickle\n",
        "except ImportError:\n",
        "    import pickle\n",
        "from PIL import Image\n",
        "\n",
        "from six.moves import range\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras import layers\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Embedding, Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2DTranspose, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils.generic_utils import Progbar\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1337)\n",
        "num_classes = 10\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vcJblmc-u3uA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_generator(latent_size):\n",
        "    cnn = Sequential()\n",
        "\n",
        "    cnn.add(Dense(3 * 3 * 384, input_dim=latent_size, activation='relu'))\n",
        "    cnn.add(Reshape((3, 3, 384)))\n",
        "\n",
        "    cnn.add(Conv2DTranspose(192, 5, strides=1, padding='valid',\n",
        "                            activation='relu',\n",
        "                            kernel_initializer='glorot_normal'))\n",
        "    cnn.add(BatchNormalization())\n",
        "\n",
        "    cnn.add(Conv2DTranspose(96, 5, strides=2, padding='same',\n",
        "                            activation='relu',\n",
        "                            kernel_initializer='glorot_normal'))\n",
        "    cnn.add(BatchNormalization())\n",
        "\n",
        "    cnn.add(Conv2DTranspose(1, 5, strides=2, padding='same',\n",
        "                            activation='tanh',\n",
        "                            kernel_initializer='glorot_normal'))\n",
        "\n",
        "    latent = Input(shape=(latent_size, ))\n",
        "\n",
        "    image_class = Input(shape=(1,), dtype='int32')\n",
        "\n",
        "    cls = Embedding(num_classes, latent_size,\n",
        "                    embeddings_initializer='glorot_normal')(image_class)\n",
        "\n",
        "    h = layers.multiply([latent, cls])\n",
        "\n",
        "    fake_image = cnn(h)\n",
        "\n",
        "    return Model([latent, image_class], fake_image)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rasz6x--u3uE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "\n",
        "    cnn = Sequential()\n",
        "\n",
        "    cnn.add(Conv2D(32, 3, padding='same', strides=2,\n",
        "                   input_shape=(28, 28, 1)))\n",
        "    cnn.add(LeakyReLU(0.2))\n",
        "    cnn.add(Dropout(0.3))\n",
        "\n",
        "    cnn.add(Conv2D(64, 3, padding='same', strides=1))\n",
        "    cnn.add(LeakyReLU(0.2))\n",
        "    cnn.add(Dropout(0.3))\n",
        "\n",
        "    cnn.add(Conv2D(128, 3, padding='same', strides=2))\n",
        "    cnn.add(LeakyReLU(0.2))\n",
        "    cnn.add(Dropout(0.3))\n",
        "\n",
        "    cnn.add(Conv2D(256, 3, padding='same', strides=1))\n",
        "    cnn.add(LeakyReLU(0.2))\n",
        "    cnn.add(Dropout(0.3))\n",
        "\n",
        "    cnn.add(Flatten())\n",
        "\n",
        "    image = Input(shape=(28, 28, 1))\n",
        "\n",
        "    features = cnn(image)\n",
        "\n",
        "    fake = Dense(1, activation='sigmoid', name='generation')(features)\n",
        "    aux = Dense(num_classes, activation='softmax', name='auxiliary')(features)\n",
        "\n",
        "    return Model(image, [fake, aux])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UDwvx6PQu3uI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2162
        },
        "outputId": "02498ace-35a1-4ded-e723-c2f20787878e"
      },
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    epochs = 10\n",
        "    batch_size = 128\n",
        "    latent_size = 100\n",
        "\n",
        "    adam_lr = 0.0002\n",
        "    adam_beta_1 = 0.5\n",
        "\n",
        "    # build the discriminator\n",
        "    print('Discriminator model:')\n",
        "    discriminator = build_discriminator()\n",
        "    discriminator.compile(\n",
        "        optimizer=Adam(lr=adam_lr, beta_1=adam_beta_1),\n",
        "        loss=['binary_crossentropy', 'sparse_categorical_crossentropy']\n",
        "    )\n",
        "    discriminator.summary()\n",
        "\n",
        "    generator = build_generator(latent_size)\n",
        "\n",
        "    latent = Input(shape=(latent_size, ))\n",
        "    image_class = Input(shape=(1,), dtype='int32')\n",
        "\n",
        "    fake = generator([latent, image_class])\n",
        "\n",
        "    discriminator.trainable = False\n",
        "    fake, aux = discriminator(fake)\n",
        "    combined = Model([latent, image_class], [fake, aux])\n",
        "\n",
        "    print('Combined model:')\n",
        "    combined.compile(\n",
        "        optimizer=Adam(lr=adam_lr, beta_1=adam_beta_1),\n",
        "        loss=['binary_crossentropy', 'sparse_categorical_crossentropy']\n",
        "    )\n",
        "    combined.summary()\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
        "    x_train = np.expand_dims(x_train, axis=-1)\n",
        "\n",
        "    x_test = (x_test.astype(np.float32) - 127.5) / 127.5\n",
        "    x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "    num_train, num_test = x_train.shape[0], x_test.shape[0]\n",
        "\n",
        "    train_history = defaultdict(list)\n",
        "    test_history = defaultdict(list)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print('Epoch {}/{}'.format(epoch, epochs))\n",
        "\n",
        "        num_batches = int(np.ceil(x_train.shape[0] / float(batch_size)))\n",
        "        progress_bar = Progbar(target=num_batches)\n",
        "\n",
        "        epoch_gen_loss = []\n",
        "        epoch_disc_loss = []\n",
        "\n",
        "        for index in range(num_batches):\n",
        "            image_batch = x_train[index * batch_size:(index + 1) * batch_size]\n",
        "            label_batch = y_train[index * batch_size:(index + 1) * batch_size]\n",
        "\n",
        "            noise = np.random.uniform(-1, 1, (len(image_batch), latent_size))\n",
        "\n",
        "            sampled_labels = np.random.randint(0, num_classes, len(image_batch))\n",
        "\n",
        "\n",
        "            generated_images = generator.predict(\n",
        "                [noise, sampled_labels.reshape((-1, 1))], verbose=0)\n",
        "\n",
        "            x = np.concatenate((image_batch, generated_images))\n",
        "\n",
        "            soft_zero, soft_one = 0, 0.95\n",
        "            y = np.array(\n",
        "                [soft_one] * len(image_batch) + [soft_zero] * len(image_batch))\n",
        "            aux_y = np.concatenate((label_batch, sampled_labels), axis=0)\n",
        "\n",
        "            disc_sample_weight = [np.ones(2 * len(image_batch)),\n",
        "                                  np.concatenate((np.ones(len(image_batch)) * 2,\n",
        "                                                  np.zeros(len(image_batch))))]\n",
        "\n",
        "            epoch_disc_loss.append(discriminator.train_on_batch(\n",
        "                x, [y, aux_y], sample_weight=disc_sample_weight))\n",
        "\n",
        "            noise = np.random.uniform(-1, 1, (2 * len(image_batch), latent_size))\n",
        "            sampled_labels = np.random.randint(0, num_classes, 2 * len(image_batch))\n",
        "\n",
        "            trick = np.ones(2 * len(image_batch)) * soft_one\n",
        "\n",
        "            epoch_gen_loss.append(combined.train_on_batch(\n",
        "                [noise, sampled_labels.reshape((-1, 1))],\n",
        "                [trick, sampled_labels]))\n",
        "\n",
        "            progress_bar.update(index + 1)\n",
        "\n",
        "        print('Testing for epoch {}:'.format(epoch))\n",
        "\n",
        "        noise = np.random.uniform(-1, 1, (num_test, latent_size))\n",
        "\n",
        "        sampled_labels = np.random.randint(0, num_classes, num_test)\n",
        "        generated_images = generator.predict(\n",
        "            [noise, sampled_labels.reshape((-1, 1))], verbose=False)\n",
        "\n",
        "        x = np.concatenate((x_test, generated_images))\n",
        "        y = np.array([1] * num_test + [0] * num_test)\n",
        "        aux_y = np.concatenate((y_test, sampled_labels), axis=0)\n",
        "\n",
        "        discriminator_test_loss = discriminator.evaluate(\n",
        "            x, [y, aux_y], verbose=False)\n",
        "\n",
        "        discriminator_train_loss = np.mean(np.array(epoch_disc_loss), axis=0)\n",
        "\n",
        "        noise = np.random.uniform(-1, 1, (2 * num_test, latent_size))\n",
        "        sampled_labels = np.random.randint(0, num_classes, 2 * num_test)\n",
        "\n",
        "        trick = np.ones(2 * num_test)\n",
        "\n",
        "        generator_test_loss = combined.evaluate(\n",
        "            [noise, sampled_labels.reshape((-1, 1))],\n",
        "            [trick, sampled_labels], verbose=False)\n",
        "\n",
        "        generator_train_loss = np.mean(np.array(epoch_gen_loss), axis=0)\n",
        "\n",
        "        train_history['generator'].append(generator_train_loss)\n",
        "        train_history['discriminator'].append(discriminator_train_loss)\n",
        "\n",
        "        test_history['generator'].append(generator_test_loss)\n",
        "        test_history['discriminator'].append(discriminator_test_loss)\n",
        "\n",
        "        print('{0:<22s} | {1:4s} | {2:15s} | {3:5s}'.format(\n",
        "            'component', *discriminator.metrics_names))\n",
        "        print('-' * 65)\n",
        "\n",
        "        ROW_FMT = '{0:<22s} | {1:<4.2f} | {2:<15.4f} | {3:<5.4f}'\n",
        "        print(ROW_FMT.format('generator (train)',\n",
        "                             *train_history['generator'][-1]))\n",
        "        print(ROW_FMT.format('generator (test)',\n",
        "                             *test_history['generator'][-1]))\n",
        "        print(ROW_FMT.format('discriminator (train)',\n",
        "                             *train_history['discriminator'][-1]))\n",
        "        print(ROW_FMT.format('discriminator (test)',\n",
        "                             *test_history['discriminator'][-1]))\n",
        "        generator.save_weights(\n",
        "            'params_generator_epoch_{0:03d}.hdf5'.format(epoch), True)\n",
        "        discriminator.save_weights(\n",
        "            'params_discriminator_epoch_{0:03d}.hdf5'.format(epoch), True)\n",
        "\n",
        "\n",
        "        num_rows = 40\n",
        "        noise = np.tile(np.random.uniform(-1, 1, (num_rows, latent_size)),\n",
        "                        (num_classes, 1))\n",
        "\n",
        "        sampled_labels = np.array([\n",
        "            [i] * num_rows for i in range(num_classes)\n",
        "        ]).reshape(-1, 1)\n",
        "\n",
        "        generated_images = generator.predict(\n",
        "            [noise, sampled_labels], verbose=0)\n",
        "\n",
        "        real_labels = y_train[(epoch - 1) * num_rows * num_classes:\n",
        "                              epoch * num_rows * num_classes]\n",
        "        indices = np.argsort(real_labels, axis=0)\n",
        "        real_images = x_train[(epoch - 1) * num_rows * num_classes:\n",
        "                              epoch * num_rows * num_classes][indices]\n",
        "\n",
        "        img = np.concatenate(\n",
        "            (generated_images,\n",
        "             np.repeat(np.ones_like(x_train[:1]), num_rows, axis=0),\n",
        "             real_images))\n",
        "\n",
        "        img = (np.concatenate([r.reshape(-1, 28)\n",
        "                               for r in np.split(img, 2 * num_classes + 1)\n",
        "                               ], axis=-1) * 127.5 + 127.5).astype(np.uint8)\n",
        "\n",
        "        Image.fromarray(img).save(\n",
        "            'plot_epoch_{0:03d}_generated.png'.format(epoch))\n",
        "\n",
        "    with open('acgan-history.pkl', 'wb') as f:\n",
        "        pickle.dump({'train': train_history, 'test': test_history}, f)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Discriminator model:\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 12544)        387840      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "generation (Dense)              (None, 1)            12545       sequential_1[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "auxiliary (Dense)               (None, 10)           125450      sequential_1[1][0]               \n",
            "==================================================================================================\n",
            "Total params: 525,835\n",
            "Trainable params: 525,835\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Combined model:\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_2 (Model)                 (None, 28, 28, 1)    2657897     input_4[0][0]                    \n",
            "                                                                 input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Model)                 [(None, 1), (None, 1 525835      model_2[1][0]                    \n",
            "==================================================================================================\n",
            "Total params: 3,183,732\n",
            "Trainable params: 2,657,321\n",
            "Non-trainable params: 526,411\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 122s 261ms/step\n",
            "Testing for epoch 1:\n",
            "component              | loss | generation_loss | auxiliary_loss\n",
            "-----------------------------------------------------------------\n",
            "generator (train)      | 1.46 | 0.9681          | 0.4968\n",
            "generator (test)       | 0.93 | 0.8674          | 0.0650\n",
            "discriminator (train)  | 1.61 | 0.6760          | 0.9297\n",
            "discriminator (test)   | 0.80 | 0.6680          | 0.1302\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 137s 292ms/step\n",
            "Testing for epoch 2:\n",
            "component              | loss | generation_loss | auxiliary_loss\n",
            "-----------------------------------------------------------------\n",
            "generator (train)      | 0.99 | 0.9530          | 0.0324\n",
            "generator (test)       | 0.84 | 0.8345          | 0.0083\n",
            "discriminator (train)  | 1.04 | 0.6878          | 0.3525\n",
            "discriminator (test)   | 0.73 | 0.6819          | 0.0526\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 87s 185ms/step\n",
            "Testing for epoch 3:\n",
            "component              | loss | generation_loss | auxiliary_loss\n",
            "-----------------------------------------------------------------\n",
            "generator (train)      | 0.85 | 0.8355          | 0.0188\n",
            "generator (test)       | 0.68 | 0.6815          | 0.0032\n",
            "discriminator (train)  | 0.94 | 0.7078          | 0.2327\n",
            "discriminator (test)   | 0.77 | 0.7359          | 0.0356\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 87s 185ms/step\n",
            "Testing for epoch 4:\n",
            "component              | loss | generation_loss | auxiliary_loss\n",
            "-----------------------------------------------------------------\n",
            "generator (train)      | 0.84 | 0.8278          | 0.0130\n",
            "generator (test)       | 0.80 | 0.7959          | 0.0031\n",
            "discriminator (train)  | 0.90 | 0.7106          | 0.1849\n",
            "discriminator (test)   | 0.75 | 0.7169          | 0.0301\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 87s 185ms/step\n",
            "Testing for epoch 5:\n",
            "component              | loss | generation_loss | auxiliary_loss\n",
            "-----------------------------------------------------------------\n",
            "generator (train)      | 0.81 | 0.8026          | 0.0091\n",
            "generator (test)       | 0.75 | 0.7451          | 0.0032\n",
            "discriminator (train)  | 0.87 | 0.7085          | 0.1580\n",
            "discriminator (test)   | 0.73 | 0.7047          | 0.0260\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 87s 185ms/step\n",
            "Testing for epoch 6:\n",
            "component              | loss | generation_loss | auxiliary_loss\n",
            "-----------------------------------------------------------------\n",
            "generator (train)      | 0.80 | 0.7927          | 0.0076\n",
            "generator (test)       | 0.73 | 0.7307          | 0.0020\n",
            "discriminator (train)  | 0.85 | 0.7075          | 0.1376\n",
            "discriminator (test)   | 0.78 | 0.7569          | 0.0227\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 87s 185ms/step\n",
            "Testing for epoch 7:\n",
            "component              | loss | generation_loss | auxiliary_loss\n",
            "-----------------------------------------------------------------\n",
            "generator (train)      | 0.80 | 0.7922          | 0.0067\n",
            "generator (test)       | 0.74 | 0.7339          | 0.0018\n",
            "discriminator (train)  | 0.83 | 0.7075          | 0.1252\n",
            "discriminator (test)   | 0.75 | 0.7325          | 0.0202\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 87s 185ms/step\n",
            "Testing for epoch 8:\n",
            "component              | loss | generation_loss | auxiliary_loss\n",
            "-----------------------------------------------------------------\n",
            "generator (train)      | 0.79 | 0.7815          | 0.0056\n",
            "generator (test)       | 0.72 | 0.7162          | 0.0006\n",
            "discriminator (train)  | 0.82 | 0.7055          | 0.1125\n",
            "discriminator (test)   | 0.73 | 0.7133          | 0.0174\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 87s 185ms/step\n",
            "Testing for epoch 9:\n",
            "component              | loss | generation_loss | auxiliary_loss\n",
            "-----------------------------------------------------------------\n",
            "generator (train)      | 0.79 | 0.7889          | 0.0046\n",
            "generator (test)       | 0.72 | 0.7143          | 0.0011\n",
            "discriminator (train)  | 0.81 | 0.7053          | 0.1021\n",
            "discriminator (test)   | 0.75 | 0.7326          | 0.0181\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 87s 185ms/step\n",
            "Testing for epoch 10:\n",
            "component              | loss | generation_loss | auxiliary_loss\n",
            "-----------------------------------------------------------------\n",
            "generator (train)      | 0.79 | 0.7818          | 0.0045\n",
            "generator (test)       | 0.72 | 0.7174          | 0.0005\n",
            "discriminator (train)  | 0.80 | 0.7041          | 0.0980\n",
            "discriminator (test)   | 0.76 | 0.7473          | 0.0163\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}